{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzcX13IQFoe4MozHtc5rAv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IPutuArcana/RAG-Komparatif-Multi-Dokumen-Temporal/blob/main/RAG_CSR_BANK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File ini dirancang untuk dijalankan di Google Colaboratory (Colab)\n",
        "# Keuntungan: Tidak memakan ruang disk lokal (Mengatasi Error \"No space left on device\")\n",
        "# Semua proses komputasi berat (Embedding & LLM Generation) berjalan di Cloud.\n",
        "\n",
        "# --- BAGIAN 1: INSTALASI DAN SETUP LINGKUNGAN ---\n",
        "# Silakan jalankan sel ini terlebih dahulu di Colab.\n",
        "# Output: Semua library terinstal.\n",
        "\n",
        "# Instalasi Libraries yang dibutuhkan\n",
        "# Kritis: Kita harus memasang library SBERT (sentence-transformers) untuk model lokal yang ringan.\n",
        "# PERBAIKAN INSTALASI: Menambahkan langchain-chroma\n",
        "!pip install --quiet pypdf langchain-text-splitters chromadb google-genai sentence-transformers numpy pandas langchain-chroma"
      ],
      "metadata": {
        "id": "AZsQsgbjQQDq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch # Import PyTorch, tapi Colab yang akan menanganinya\n",
        "from pathlib import Path\n",
        "from pypdf import PdfReader\n",
        "\n",
        "# Import RAG/Vector Store Components\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "# PERBAIKAN IMPOR: Mengganti dari langchain_community menjadi langchain_chroma\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from sentence_transformers import SentenceTransformer # Untuk Embedding Lokal (Ringan)\n",
        "\n",
        "# Import API Clients\n",
        "# from langchain_openai import OpenAIEmbeddings # TIDAK DIPAKAI LAGI\n",
        "from google import genai\n",
        "from google.genai.errors import APIError\n",
        "\n",
        "# --- Konfigurasi dan Variabel Global ---\n",
        "# HANYA PERLU GEMINI API KEY\n",
        "GEMINI_API_KEY = \"AIzaSyC9IdJJRi7iFE-muSjJBxQpkt8nDl59kYM\"\n",
        "OPENAI_API_KEY = \"\" # Dihapus / Tidak digunakan\n",
        "\n",
        "# Model Embedding Lokal yang SANGAT RINGAN (<200MB)\n",
        "# Idealnya menggunakan all-MiniLM-L6-v2, yang tidak memicu instalasi Torch besar\n",
        "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "# Folder di Google Drive tempat Anda mengunggah PDF\n",
        "DRIVE_FOLDER_NAME = \"Project_RAG_CSR_Bank\"\n",
        "VECTOR_STORE_PATH = \"chroma_db_csr_bank\"\n",
        "\n",
        "EMITEN_LIST = [\"BBCA\", \"BBRI\", \"BMRI\", \"BBNI\", \"BNGA\"]\n",
        "YEARS_TO_PROCESS = [\"2023\", \"2024\"] # Asumsi 2 tahun data\n",
        "\n",
        "# LLM untuk Generation (Gemini)\n",
        "LLM_MODEL = \"gemini-2.5-flash-preview-09-2025\"\n",
        "\n",
        "# Klien API (Harus diinisialisasi)\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "T1rsLFUmXP-Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- BAGIAN 2: AUTENTIKASI DAN MEMUAT DATA PDF DARI GOOGLE DRIVE ---\n",
        "# Jalankan sel ini. Ikuti instruksi untuk menghubungkan Colab ke Drive Anda.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PDF_DIR = Path(f\"/content/drive/MyDrive/{DRIVE_FOLDER_NAME}\")\n",
        "PROCESSED_DATA_DIR = Path(\"/content/processed_data\")\n",
        "PROCESSED_DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
        "    \"\"\"Ekstraksi teks dari file PDF.\"\"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error membaca {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def generate_chunks_with_metadata(emiten_code: str, year: str, text: str) -> list:\n",
        "    \"\"\"Membuat chunks teks dengan metadata emiten dan tahun.\"\"\"\n",
        "    # Ukuran chunk disesuaikan untuk dokumen panjang\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1200,\n",
        "        chunk_overlap=200,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    chunks = text_splitter.create_documents([text])\n",
        "\n",
        "    chunk_list = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_data = {\n",
        "            \"text\": chunk.page_content,\n",
        "            \"metadata\": {\n",
        "                \"emiten\": emiten_code,\n",
        "                \"tahun\": year,\n",
        "                \"dokumen_id\": f\"{emiten_code}_CSR_{year}\",\n",
        "                # Metadata ini KRUSIAL untuk komparasi!\n",
        "            }\n",
        "        }\n",
        "        # Konversi ke format LangChain Document\n",
        "        chunk_list.append(Document(page_content=chunk_data['text'], metadata=chunk_data['metadata']))\n",
        "\n",
        "    return chunk_list\n",
        "\n",
        "all_documents = []\n",
        "print(\"\\n--- Memulai Pre-processing 10 Dokumen CSR ---\")\n",
        "\n",
        "for emiten in EMITEN_LIST:\n",
        "    for year in YEARS_TO_PROCESS:\n",
        "        file_name = f\"{emiten}_CSR_{year}.pdf\"\n",
        "        pdf_path = PDF_DIR / file_name\n",
        "\n",
        "        if pdf_path.exists():\n",
        "            print(f\"1. Memproses file: {file_name}\")\n",
        "            raw_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "            if len(raw_text) < 1000:\n",
        "                 print(f\"   [PERINGATAN] Teks terlalu pendek. Periksa file {file_name}.\")\n",
        "\n",
        "            chunks = generate_chunks_with_metadata(emiten, year, raw_text)\n",
        "            all_documents.extend(chunks)\n",
        "            print(f\"   -> Dihasilkan {len(chunks)} chunks untuk {emiten} ({year}).\")\n",
        "        else:\n",
        "            print(f\"   [SKIP] File {file_name} tidak ditemukan di Google Drive.\")\n",
        "\n",
        "print(f\"\\n--- Selesai Pre-processing. Total {len(all_documents)} chunks siap di-index. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6vwhxk7XTjp",
        "outputId": "bfc5146c-4dbf-4b17-d0a0-58bfbe98716b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "--- Memulai Pre-processing 10 Dokumen CSR ---\n",
            "1. Memproses file: BBCA_CSR_2023.pdf\n",
            "   -> Dihasilkan 370 chunks untuk BBCA (2023).\n",
            "1. Memproses file: BBCA_CSR_2024.pdf\n",
            "   -> Dihasilkan 393 chunks untuk BBCA (2024).\n",
            "1. Memproses file: BBRI_CSR_2023.pdf\n",
            "   -> Dihasilkan 602 chunks untuk BBRI (2023).\n",
            "1. Memproses file: BBRI_CSR_2024.pdf\n",
            "   -> Dihasilkan 783 chunks untuk BBRI (2024).\n",
            "1. Memproses file: BMRI_CSR_2023.pdf\n",
            "   -> Dihasilkan 721 chunks untuk BMRI (2023).\n",
            "1. Memproses file: BMRI_CSR_2024.pdf\n",
            "   -> Dihasilkan 842 chunks untuk BMRI (2024).\n",
            "1. Memproses file: BBNI_CSR_2023.pdf\n",
            "   -> Dihasilkan 354 chunks untuk BBNI (2023).\n",
            "1. Memproses file: BBNI_CSR_2024.pdf\n",
            "   -> Dihasilkan 427 chunks untuk BBNI (2024).\n",
            "1. Memproses file: BNGA_CSR_2023.pdf\n",
            "   -> Dihasilkan 309 chunks untuk BNGA (2023).\n",
            "1. Memproses file: BNGA_CSR_2024.pdf\n",
            "   -> Dihasilkan 460 chunks untuk BNGA (2024).\n",
            "\n",
            "--- Selesai Pre-processing. Total 5261 chunks siap di-index. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BAGIAN 3: INDEXING (EMBEDDING) KE CHROMA DB ---\n",
        "# Ini adalah langkah indexing komputasi berat. Dijalankan di RAM Colab.\n",
        "# Jalankan sel ini.\n",
        "\n",
        "try:\n",
        "    # 1. Inisialisasi Model Embedding Lokal (Ringan)\n",
        "    print(f\"\\n--- Memuat Model Embedding Lokal: {EMBEDDING_MODEL_NAME} ---\")\n",
        "    embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
        "\n",
        "    # Wrap SBERT model ke dalam format yang dipahami LangChain Chroma\n",
        "    class SBERTEmbeddings:\n",
        "        def embed_documents(self, texts):\n",
        "            return embedding_model.encode(texts, convert_to_numpy=True).tolist()\n",
        "        def embed_query(self, text):\n",
        "            return embedding_model.encode([text], convert_to_numpy=True).tolist()[0]\n",
        "\n",
        "    embeddings = SBERTEmbeddings()\n",
        "\n",
        "    # 2. Membuat Vector Store ChromaDB\n",
        "    print(f\"\\n--- Membuat Vector Store ChromaDB dari {len(all_documents)} dokumen ---\")\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=all_documents,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=VECTOR_STORE_PATH # Disimpan di Colab lokal\n",
        "    )\n",
        "    # PERBAIKAN: Menghapus .persist() yang sudah usang di versi ChromaDB ini.\n",
        "    # Data akan disimpan secara otomatis atau hanya disimpan sementara di RAM Colab.\n",
        "    # vectorstore.persist()\n",
        "    print(\"--- Vector Store Berhasil Dibuat dan Indexing Selesai ---\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n[ERROR KRITIS PADA INDEXING] Pastikan koneksi internet stabil dan model {EMBEDDING_MODEL_NAME} berhasil dimuat.\")\n",
        "    print(f\"Detail Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-6iU7kDXaf5",
        "outputId": "a0a64e41-4b24-4015-e44b-2c6d941a9d1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Memuat Model Embedding Lokal: all-MiniLM-L6-v2 ---\n",
            "\n",
            "--- Membuat Vector Store ChromaDB dari 5261 dokumen ---\n",
            "--- Vector Store Berhasil Dibuat dan Indexing Selesai ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BAGIAN 4: FUNGSI GENERASI LLM & UJI COBA RAG KOMPARATIF ---\n",
        "# Jalankan sel ini untuk menguji fungsi RAG Komparatif Anda.\n",
        "\n",
        "def generate_content_with_retry(prompt: str, max_retries: int = 5, initial_delay: int = 2) -> str:\n",
        "    \"\"\"Melakukan API call ke Gemini dengan exponential backoff.\"\"\"\n",
        "    if not GEMINI_API_KEY:\n",
        "         return \"Error: Gemini API Key tidak ditemukan. Generasi LLM dilewati.\"\n",
        "\n",
        "    delay = initial_delay\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            # Panggil Gemini API\n",
        "            response = client.models.generate_content(\n",
        "                model=LLM_MODEL,\n",
        "                contents=prompt,\n",
        "            )\n",
        "            return response.text\n",
        "        except APIError as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"API Error: {e}. Retrying in {delay}s...\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2  # Exponential backoff\n",
        "            else:\n",
        "                return f\"Gagal menghasilkan konten setelah {max_retries} percobaan. Error: {e}\"\n",
        "        except Exception as e:\n",
        "            return f\"Error umum saat memanggil API: {e}\"\n",
        "    return \"Gagal menghasilkan konten.\"\n",
        "\n",
        "# PERBAIKAN KRITIS: Mengganti parameter 'year' menjadi 'year_a' dan 'year_b'\n",
        "def perform_comparative_rag(vectorstore: Chroma, query: str, emiten_a: str, emiten_b: str, year_a: str = \"2023\", year_b: str = \"2023\"):\n",
        "    \"\"\"\n",
        "    Melakukan RAG Komparatif: Retrieval dari dua emiten/tahun, LLM membandingkan.\n",
        "    \"\"\"\n",
        "\n",
        "    # Fungsi helper untuk retrieval ber-filter\n",
        "    def retrieve_context(emiten_code, year):\n",
        "        # Filter metadata untuk mengambil dokumen dari emiten dan tahun spesifik\n",
        "        # Menggunakan operator $and untuk dua kondisi filter (Fix ValueError)\n",
        "        metadata_filter = {\n",
        "            \"$and\": [\n",
        "                {\"emiten\": emiten_code},\n",
        "                {\"tahun\": year}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Retrieval dari Chroma DB. k=4 untuk mengambil 4 chunk terbaik\n",
        "        # Menggunakan as_retriever() untuk mengatasi TypeError: got multiple values for keyword argument 'where'\n",
        "        retriever = vectorstore.as_retriever(\n",
        "            search_kwargs={\"k\": 4, \"filter\": metadata_filter}\n",
        "        )\n",
        "\n",
        "        # PERBAIKAN ATTRIBUTE ERROR: Mengganti get_relevant_documents() dengan invoke()\n",
        "        docs = retriever.invoke(query)\n",
        "\n",
        "        # Gabungkan teks dan sumber untuk verifikasi\n",
        "        context = []\n",
        "        for doc in docs:\n",
        "            context.append(f\"[{doc.metadata['emiten']} {doc.metadata['tahun']}] {doc.page_content}\")\n",
        "\n",
        "        return \"\\n---\\n\".join(context)\n",
        "\n",
        "    # 1. Retrieval untuk Emiten A (Tahun A) dan Emiten B (Tahun B)\n",
        "    # PERBAIKAN: Menggunakan year_a dan year_b\n",
        "    context_a = retrieve_context(emiten_a, year_a)\n",
        "    context_b = retrieve_context(emiten_b, year_b)\n",
        "\n",
        "    # 2. Prompt Engineering untuk Komparasi (meminta output terstruktur)\n",
        "    prompt_template = \"\"\"\n",
        "        Anda adalah Analis CSR profesional. Tugas Anda adalah membandingkan\n",
        "        kebijakan CSR dari dua laporan yang berbeda berdasarkan konteks yang diberikan.\n",
        "\n",
        "        Pertanyaan Analisis: {query}\n",
        "\n",
        "        [LAPORAN A: {emiten_a} TAHUN {year_a}]\n",
        "        {context_a}\n",
        "\n",
        "        [LAPORAN B: {emiten_b} TAHUN {year_b}]\n",
        "        {context_b}\n",
        "\n",
        "        Instruksi Jawaban:\n",
        "        1. Berikan jawaban komparatif yang ringkas (maksimal 3 paragraf).\n",
        "        2. Harus ada perbandingan yang jelas antara Laporan A dan Laporan B.\n",
        "        3. Wajib sertakan kutipan atau referensi bukti dari konteks yang mendukung perbandingan Anda (Contoh: [{emiten_a} {year_a}] atau [{emiten_b} {year_b}]).\n",
        "\n",
        "        --- JAWABAN ANALISIS KOMPARATIF DIMULAI DI SINI ---\n",
        "        \"\"\"\n",
        "\n",
        "    # PERBAIKAN: Memasukkan year_a dan year_b ke dalam format\n",
        "    full_prompt = prompt_template.format(\n",
        "        query=query,\n",
        "        emiten_a=emiten_a,\n",
        "        year_a=year_a,\n",
        "        context_a=context_a,\n",
        "        emiten_b=emiten_b,\n",
        "        year_b=year_b,\n",
        "        context_b=context_b\n",
        "    )\n",
        "\n",
        "    print(f\"\\n--- Melakukan Generasi LLM Komparatif ({emiten_a} {year_a} vs {emiten_b} {year_b}) ---\")\n",
        "\n",
        "    llm_response = generate_content_with_retry(full_prompt)\n",
        "    return llm_response\n",
        "\n",
        "# --- EKSEKUSI UJI COBA RAG ---\n",
        "# Anda bisa mengganti emiten dan tahun di sini untuk uji coba.\n",
        "\n",
        "# Contoh 1: Komparasi Lintas Emiten\n",
        "query_csr_1 = \"Bandingkan program CSR Lingkungan (E) antara Mandiri dan BNI di tahun 2023. Siapa yang lebih fokus pada pendanaan proyek hijau?\"\n",
        "response_1 = perform_comparative_rag(\n",
        "    vectorstore,\n",
        "    query=query_csr_1,\n",
        "    emiten_a=\"BMRI\",\n",
        "    emiten_b=\"BBNI\",\n",
        "    year_a=\"2023\", # Mengubah parameter year menjadi year_a (year_b otomatis 2023)\n",
        ")\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(f\"PERTANYAAN 1: {query_csr_1}\")\n",
        "print(\"=======================================================\")\n",
        "print(response_1)\n",
        "print(\"=======================================================\\n\")\n",
        "\n",
        "# Contoh 2: Komparasi Temporal (Pergeseran Prioritas)\n",
        "# PERBAIKAN: Contoh 2 sekarang dapat dijalankan\n",
        "query_csr_2 = \"Apa perbedaan signifikan pada fokus CSR Sosial (S) yang dilakukan BRI dari tahun 2023 ke 2024?\"\n",
        "response_2 = perform_comparative_rag(\n",
        "    vectorstore,\n",
        "    query=query_csr_2,\n",
        "    emiten_a=\"BBRI\",\n",
        "    emiten_b=\"BBRI\", # Membandingkan dengan dirinya sendiri\n",
        "    year_a=\"2023\",\n",
        "    year_b=\"2024\"\n",
        ")\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(f\"PERTANYAAN 2: {query_csr_2}\")\n",
        "print(\"=======================================================\")\n",
        "print(response_2)\n",
        "print(\"=======================================================\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46Mvl3smXf3K",
        "outputId": "9b184ab8-0a1f-4453-f8e1-1ec027c5e70d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Melakukan Generasi LLM Komparatif (BMRI 2023 vs BBNI 2023) ---\n",
            "\n",
            "=======================================================\n",
            "PERTANYAAN 1: Bandingkan program CSR Lingkungan (E) antara Mandiri dan BNI di tahun 2023. Siapa yang lebih fokus pada pendanaan proyek hijau?\n",
            "=======================================================\n",
            "Berdasarkan konteks laporan yang tersedia, Bank Mandiri (BMRI) menunjukkan fokus yang lebih eksplisit terhadap integrasi aspek Lingkungan (E) ke dalam fungsi pembiayaan intinya, menjadikannya pihak yang lebih fokus pada pendanaan proyek hijau (atau manajemen risiko lingkungan pembiayaan). Bukti kunci terletak pada penyebutan langsung strategi keberlanjutan operasional yang mencakup **\"Pengendalian Emisi dari Kegiatan Pembiayaan\"** [BMRI 2023]. Frasa ini mengindikasikan bahwa BMRI secara formal mengakui dan berupaya mengelola dampak lingkungan (emisi) yang timbul dari portofolio pinjaman mereka, yang merupakan komponen fundamental dari kerangka *sustainable financing* (pendanaan hijau).\n",
            "\n",
            "Sebaliknya, laporan dari Bank BNI (BBNI) yang disajikan, meskipun mengalokasikan dana besar untuk program Tanggung Jawab Sosial dan Lingkungan (TJSL) sebesar Rp129,8 miliar, cenderung memprioritaskan pilar Sosial (S) dan Ekonomi. Program-program utama yang dijelaskan, seperti pengembangan infrastruktur dan kapabilitas pada Program KAWAN (Desa Wisata) dan pengelolaan Rumah BUMN, difokuskan pada peningkatan kesejahteraan hidup, perubahan perilaku, dan dukungan terhadap UMKM [BBNI 2023]. Meskipun Desa Wisata dapat memiliki komponen lingkungan, fokus yang ditekankan dalam kutipan tersebut adalah aspek sosial dan ekonomi komunitas, dan tidak terdapat referensi langsung mengenai pembiayaan spesifik untuk proyek mitigasi iklim atau proyek ramah lingkungan (pendanaan hijau).\n",
            "\n",
            "Sebagai kesimpulan, dalam konteks perbandingan fokus pendanaan proyek hijau, Bank Mandiri menampilkan fokus yang lebih kuat dan terstruktur dalam laporan keberlanjutannya. Penekanan BMRI pada \"Pengendalian Emisi dari Kegiatan Pembiayaan\" menunjukkan upaya untuk mengintegrasikan metrik lingkungan ke dalam keputusan pembiayaan operasionalnya [BMRI 2023]. Sementara BNI menunjukkan komitmen TJSL yang kuat, bukti yang disajikan lebih mengarah pada pembangunan komunitas dan dukungan sosial-ekonomi [BBNI 2023].\n",
            "=======================================================\n",
            "\n",
            "\n",
            "--- Melakukan Generasi LLM Komparatif (BBRI 2023 vs BBRI 2024) ---\n",
            "\n",
            "=======================================================\n",
            "PERTANYAAN 2: Apa perbedaan signifikan pada fokus CSR Sosial (S) yang dilakukan BRI dari tahun 2023 ke 2024?\n",
            "=======================================================\n",
            "Analisis komparatif menunjukkan adanya pergeseran signifikan dalam fokus CSR Sosial (S) BRI, dari orientasi pada mekanisme pendanaan spesifik untuk inklusi keuangan di tahun 2023, menuju kerangka kerja tata kelola yang lebih luas dan komitmen terhadap standar global pada tahun 2024.\n",
            "\n",
            "Pada Laporan 2023, fokus sosial BBRI sangat terpusat pada *output* dan alokasi dana yang diatur melalui instrumen keuangan. Kebijakan sosial utamanya diwujudkan melalui \"Surat Berharga untuk Tujuan Pembiayaan Inklusif,\" khususnya Medium Term Notes (MTN) yang hasilnya secara penuh dialokasikan untuk pembiayaan inklusif. Sasaran sosialnya spesifik: penyediaan dana untuk UMKM, Korporasi UMKM, dan/atau Perorangan Berpenghasilan Rendah (PBR) [BBRI 2023]. Ini mencerminkan pendekatan yang sangat terstruktur dan terukur berdasarkan kepatuhan terhadap Peraturan Bank Indonesia tentang Rasio Pembiayaan Inklusif Makroprudensial.\n",
            "\n",
            "Sebaliknya, pada Laporan 2024, fokus sosial bergeser ke kerangka kerja strategis, etika bisnis, dan integrasi isu sosial di tingkat tata kelola. BRI menekankan \"Tata Kelola yang Bertanggung Jawab\" dengan praktik *transparency, accountability, responsibility, independence, dan fairness* [BBRI 2024]. Komitmen sosial diintegrasikan melalui \"Rencana Aksi Keuangan Berkelanjutan (RAKB) Tahun 2024-2028,\" yang secara tegas mencakup pengelolaan \"isu-isu sosial dan perubahan iklim\" [BBRI 2024]. Peningkatan signifikan terlihat pada adopsi standar internasional melalui keanggotaan United Nations Global Compact (UNGC) sebagai upaya memperkuat komitmen penerapan keuangan berkelanjutan dan kontribusi pada pencapaian SDGs [BBRI 2024].\n",
            "\n",
            "Secara ringkas, perbedaan signifikan terletak pada level implementasi: 2023 menekankan aksi finansial konkret (pembiayaan inklusif melalui MTN) untuk kelompok sasaran spesifik, sementara 2024 menunjukkan peningkatan kematangan strategis dengan fokus pada internalisasi etika (Tata Kelola yang Bertanggung Jawab) dan pelembagaan komitmen sosial melalui RAKB jangka panjang serta aliansi global (UNGC), yang menggeser fokus dari transaksi tunggal ke manajemen risiko dan peluang sosial yang komprehensif.\n",
            "=======================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}